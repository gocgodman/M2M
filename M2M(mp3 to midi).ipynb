{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gocgodman/M2M/blob/main/M2M(mp3%20to%20midi).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 셀 1: 필요한 패키지 설치 (한 번만 실행)\n",
        "!pip install piano_transcription_inference\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # GPU 런타임일 경우\n",
        "\n",
        "!pip install -q yt-dlp gdown gradio pretty_midi librosa numpy soundfile pyfluidsynth\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq ffmpeg fluidsynth p7zip-full || true"
      ],
      "metadata": {
        "id": "FdYMrU9lG5sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, glob, shutil, zipfile, tarfile, subprocess\n",
        "import gdown\n",
        "\n",
        "# 기본 경로 설정\n",
        "WORK_ROOT = \"/content/ytd_pipeline_work\"\n",
        "os.makedirs(WORK_ROOT, exist_ok=True)\n",
        "\n",
        "DRIVE_SF2_DIR = \"/content/drive/MyDrive/sf2_library\"       # 내 드라이브 sf2 폴더\n",
        "DRIVE_RESULTS_DIR = \"/content/drive/MyDrive/ytd_pipeline_results\"\n",
        "os.makedirs(DRIVE_SF2_DIR, exist_ok=True)\n",
        "os.makedirs(DRIVE_RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print(\"WORK_ROOT:\", WORK_ROOT)\n",
        "print(\"DRIVE_SF2_DIR:\", DRIVE_SF2_DIR)\n",
        "print(\"DRIVE_RESULTS_DIR:\", DRIVE_RESULTS_DIR)\n",
        "\n",
        "# 공유 폴더 ID (필요할 때만 사용)\n",
        "SHARED_FOLDER_ID = \"1JkTMvPwM_XURqG2114n4Qj0rR83WEucL\"\n",
        "OUT_DIR = \"/content/sf2_from_shared\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# 공유 폴더에서 다운로드 시도\n",
        "if SHARED_FOLDER_ID:\n",
        "    try:\n",
        "        gdown.download_folder(id=SHARED_FOLDER_ID, output=OUT_DIR, quiet=False, use_cookies=False)\n",
        "    except Exception as e:\n",
        "        print(\"공유 폴더 다운로드 실패:\", e)\n",
        "\n",
        "# 압축 해제 함수\n",
        "def try_extract_archive(path, dest):\n",
        "    path_lower = path.lower()\n",
        "    os.makedirs(dest, exist_ok=True)\n",
        "    try:\n",
        "        if path_lower.endswith(\".zip\"):\n",
        "            with zipfile.ZipFile(path, 'r') as zf:\n",
        "                zf.extractall(dest); return True\n",
        "        if path_lower.endswith((\".tar.gz\", \".tgz\", \".tar\")):\n",
        "            with tarfile.open(path, 'r:*') as tf:\n",
        "                tf.extractall(dest); return True\n",
        "        if path_lower.endswith(\".7z\"):\n",
        "            cmd = ['7z', 'x', '-y', '-o' + dest, path]\n",
        "            subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE); return True\n",
        "    except Exception as e:\n",
        "        print(\"압축 해제 실패:\", e)\n",
        "    return False\n",
        "\n",
        "# 내 드라이브 + 공유 폴더 모두 탐색 → 압축파일 해제\n",
        "for root, dirs, files in os.walk(DRIVE_SF2_DIR):\n",
        "    for fn in files:\n",
        "        if fn.lower().endswith((\".zip\", \".tar.gz\", \".tgz\", \".tar\", \".7z\")):\n",
        "            extract_dest = os.path.join(root, fn + \"_extracted\")\n",
        "            try_extract_archive(os.path.join(root, fn), extract_dest)\n",
        "\n",
        "for root, dirs, files in os.walk(OUT_DIR):\n",
        "    for fn in files:\n",
        "        if fn.lower().endswith((\".zip\", \".tar.gz\", \".tgz\", \".tar\", \".7z\")):\n",
        "            extract_dest = os.path.join(root, fn + \"_extracted\")\n",
        "            try_extract_archive(os.path.join(root, fn), extract_dest)\n",
        "\n",
        "# sf2 파일 수집\n",
        "local_sf2_files = glob.glob(os.path.join(DRIVE_SF2_DIR, \"**/*.sf2\"), recursive=True)\n",
        "local_names = {os.path.basename(f) for f in local_sf2_files}\n",
        "\n",
        "shared_sf2_files = glob.glob(os.path.join(OUT_DIR, \"**/*.sf2\"), recursive=True)\n",
        "\n",
        "print(\"내 드라이브 sf2 수:\", len(local_sf2_files))\n",
        "print(\"공유 드라이브 sf2 수:\", len(shared_sf2_files))\n",
        "\n",
        "# 공유 드라이브에서 내 드라이브에 없는 파일만 복사\n",
        "copied = []\n",
        "for p in shared_sf2_files:\n",
        "    fname = os.path.basename(p)\n",
        "    if fname in local_names:\n",
        "        print(\"이미 존재 → 건너뜀:\", fname)\n",
        "        continue\n",
        "    dest = os.path.join(DRIVE_RESULTS_DIR, fname)\n",
        "    try:\n",
        "        shutil.copy(p, dest)\n",
        "        copied.append(dest)\n",
        "    except Exception as e:\n",
        "        print(\"복사 실패:\", p, e)\n",
        "\n",
        "print(\"새로 복사된 sf2 수:\", len(copied))\n",
        "for f in copied:\n",
        "    print(\" -\", f)"
      ],
      "metadata": {
        "id": "EvJEABCmHCZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 통합 셀: ByteDance 전사 + 경량 페달 검출 통합 버전\n",
        "# 실행 환경: Colab (GPU 권장). 사전 설치: piano_transcription_inference, torch, librosa, pretty_midi 등.\n",
        "\n",
        "import os, sys, time, uuid, json, glob, shutil, zipfile, subprocess, traceback\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import pretty_midi\n",
        "from scipy.ndimage import uniform_filter1d, binary_closing\n",
        "\n",
        "# Torch는 경량 페달 모델(선택적)에서 사용\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ---------------- 결과/작업 폴더 ----------------\n",
        "DRIVE_RESULTS_DIR = \"/content/drive/MyDrive/ytd_pipeline_results\"\n",
        "WORK_ROOT = \"/content/ytd_pipeline_work\"\n",
        "STATE_FILE = os.path.join(DRIVE_RESULTS_DIR, \"pipeline_state.json\")\n",
        "os.makedirs(DRIVE_RESULTS_DIR, exist_ok=True)\n",
        "os.makedirs(WORK_ROOT, exist_ok=True)\n",
        "\n",
        "# ---------------- 유틸리티 ----------------\n",
        "def run_cmd(cmd, check=False):\n",
        "    proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if check and proc.returncode != 0:\n",
        "        raise RuntimeError(f\"Command failed: {' '.join(cmd)}\\nSTDOUT:{proc.stdout}\\nSTDERR:{proc.stderr}\")\n",
        "    return proc.returncode, proc.stdout, proc.stderr\n",
        "\n",
        "def remove_extension(filepath):\n",
        "    return \".\".join(os.path.basename(filepath).split('.')[:-1])\n",
        "\n",
        "# ---------------- ByteDance 전사 (piano_transcription_inference) ----------------\n",
        "# 설치: !pip install piano_transcription_inference\n",
        "from piano_transcription_inference import PianoTranscription, sample_rate, load_audio\n",
        "_transcriptor = PianoTranscription(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def transcribe_file(input_path, outfolder='.'):\n",
        "    \"\"\"\n",
        "    piano_transcription_inference 모델로 오디오 -> MIDI 변환.\n",
        "    outfolder에 mid 파일 생성 후 경로 반환.\n",
        "    \"\"\"\n",
        "    base = remove_extension(input_path)\n",
        "    out_mid = os.path.join(outfolder, base + \".mid\")\n",
        "    audio, _ = load_audio(input_path, sr=sample_rate)\n",
        "    _transcriptor.transcribe(audio, out_mid)\n",
        "    return out_mid\n",
        "\n",
        "# ---------------- 기존 yt-dlp 헬퍼 ----------------\n",
        "def expand_playlist_to_video_urls(playlist_url):\n",
        "    cmd = [\"yt-dlp\", \"--flat-playlist\", \"-J\", playlist_url]\n",
        "    code, out, err = run_cmd(cmd)\n",
        "    if code != 0:\n",
        "        raise RuntimeError(f\"yt-dlp playlist expand failed: {err}\")\n",
        "    j = json.loads(out)\n",
        "    entries = j.get(\"entries\", [])\n",
        "    urls = []\n",
        "    for e in entries:\n",
        "        vid = e.get(\"id\")\n",
        "        if vid:\n",
        "            urls.append(f\"https://www.youtube.com/watch?v={vid}\")\n",
        "    return urls\n",
        "\n",
        "def download_youtube_audio_single(url, outdir, fmt=\"mp3\", audio_bitrate=\"192K\"):\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    out_template = os.path.join(outdir, \"%(playlist_index)s-%(title)s.%(ext)s\")\n",
        "    cmd = [\"yt-dlp\", \"-x\", \"--audio-format\", fmt, \"--audio-quality\", audio_bitrate, \"-o\", out_template, url]\n",
        "    code, out, err = run_cmd(cmd)\n",
        "    files = sorted(glob.glob(os.path.join(outdir, f\"*.{fmt}\")))\n",
        "    if not files:\n",
        "        raise RuntimeError(f\"No audio file produced by yt-dlp for {url}. yt-dlp stderr: {err}\")\n",
        "    return files[-1]\n",
        "\n",
        "# ---------------- 기존 페달 검출(규칙 기반) ----------------\n",
        "def compute_spectral_flux(y, sr, hop_length, n_fft=2048):\n",
        "    S = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length))\n",
        "    S_norm = S / (np.sum(S, axis=0, keepdims=True) + 1e-8)\n",
        "    flux = np.sqrt(np.sum(np.diff(S_norm, axis=1).clip(min=0)**2, axis=0))\n",
        "    return np.concatenate(([0.0], flux))\n",
        "\n",
        "def detect_pedal_rule(audio_path,\n",
        "                      sr=22050,\n",
        "                      hop_length=512,\n",
        "                      low_freq_cut=500,\n",
        "                      energy_smooth=0.5,\n",
        "                      on_z=1.0,\n",
        "                      off_z=0.7,\n",
        "                      min_event_len=0.06,\n",
        "                      merge_gap=0.06,\n",
        "                      closing_size=3):\n",
        "    \"\"\"\n",
        "    규칙 기반 페달 검출: 빠르고 가벼움. (기본 동작)\n",
        "    \"\"\"\n",
        "    y, _ = librosa.load(audio_path, sr=sr, mono=True)\n",
        "    frame_energy = librosa.feature.rms(y=y, frame_length=2048, hop_length=hop_length)[0]\n",
        "    S = np.abs(librosa.stft(y, n_fft=2048, hop_length=hop_length))\n",
        "    freqs = librosa.fft_frequencies(sr=sr, n_fft=2048)\n",
        "    low_idx = np.where(freqs <= low_freq_cut)[0]\n",
        "    low_energy = S[low_idx, :].sum(axis=0) if len(low_idx) > 0 else np.zeros_like(frame_energy)\n",
        "    e = frame_energy / (frame_energy.max() + 1e-8)\n",
        "    le = low_energy / (low_energy.max() + 1e-8) if low_energy.max() > 0 else low_energy\n",
        "    combined = 0.6 * le + 0.4 * e\n",
        "    window = int(max(1, energy_smooth * (sr / hop_length)))\n",
        "    combined_smooth = uniform_filter1d(combined, size=window)\n",
        "    mu = combined_smooth.mean(); sigma = combined_smooth.std() + 1e-8\n",
        "    on_thr = mu + on_z * sigma; off_thr = mu + off_z * sigma\n",
        "    mask = np.zeros_like(combined_smooth, dtype=bool)\n",
        "    state = False\n",
        "    for i, v in enumerate(combined_smooth):\n",
        "        if not state and v >= on_thr:\n",
        "            state = True; mask[i] = True\n",
        "        elif state:\n",
        "            mask[i] = True\n",
        "            if v < off_thr:\n",
        "                state = False\n",
        "    if closing_size > 1:\n",
        "        mask = binary_closing(mask, structure=np.ones(closing_size))\n",
        "    times = librosa.frames_to_time(np.arange(len(mask)), sr=sr, hop_length=hop_length)\n",
        "    events = []; prev=False; start=None\n",
        "    for t,m in zip(times, mask):\n",
        "        if m and not prev: start=t\n",
        "        if (not m) and prev and start is not None:\n",
        "            events.append((start,t)); start=None\n",
        "        prev=m\n",
        "    if prev and start is not None: events.append((start,times[-1]))\n",
        "    filtered=[]\n",
        "    for s,e in events:\n",
        "        if (e-s) >= min_event_len:\n",
        "            if filtered and s - filtered[-1][1] <= merge_gap:\n",
        "                filtered[-1] = (filtered[-1][0], e)\n",
        "            else:\n",
        "                filtered.append((s,e))\n",
        "    return filtered\n",
        "\n",
        "# ---------------- 경량 PedalCNN (선택적 보조 모델) ----------------\n",
        "class PedalCNN(nn.Module):\n",
        "    def __init__(self, in_ch=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_ch, 16, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(16)\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.fc = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool1d(x, 2)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool1d(x, 2)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = x.mean(dim=2)\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x).squeeze(-1)\n",
        "\n",
        "def extract_frame_features(y, sr=22050, hop_length=512, n_mels=40):\n",
        "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=hop_length, n_mels=n_mels)\n",
        "    logS = librosa.power_to_db(S, ref=np.max)\n",
        "    return logS  # (n_mels, T)\n",
        "\n",
        "def predict_pedal_with_model(audio_path, model, device='cpu', sr=22050, hop_length=512, threshold=0.5):\n",
        "    \"\"\"\n",
        "    간단 보조 추론: 모델이 전체 파일에 대해 페달 존재를 판단하면 규칙 기반으로 구간 추출.\n",
        "    (모델을 프레임 단위로 출력하도록 바꾸면 더 정교하게 사용 가능)\n",
        "    \"\"\"\n",
        "    y, _ = librosa.load(audio_path, sr=sr, mono=True)\n",
        "    feats = extract_frame_features(y, sr=sr, hop_length=hop_length)  # (n_mels, T)\n",
        "    X = torch.tensor(feats[np.newaxis, :, :], dtype=torch.float32)  # (1, n_mels, T)\n",
        "    X = X.mean(dim=1, keepdim=True)  # (1,1,T)\n",
        "    model.to(device); model.eval()\n",
        "    with torch.no_grad():\n",
        "        prob = float(model(X.to(device)).cpu().numpy())\n",
        "    if prob >= threshold:\n",
        "        events = detect_pedal_rule(audio_path, sr=sr, hop_length=hop_length)\n",
        "    else:\n",
        "        events = []\n",
        "    return events\n",
        "\n",
        "def detect_pedal_lightweight(audio_path,\n",
        "                             use_model=False,\n",
        "                             model_path=None,\n",
        "                             device='cpu',\n",
        "                             sr=22050,\n",
        "                             hop_length=512,\n",
        "                             rule_params=None,\n",
        "                             model_threshold=0.5):\n",
        "    \"\"\"\n",
        "    통합 페달 검출기: 규칙 기반 우선, 필요시 경량 모델로 보강.\n",
        "    반환: [(start,end), ...]\n",
        "    \"\"\"\n",
        "    if rule_params is None:\n",
        "        rule_params = {}\n",
        "    rule_events = detect_pedal_rule(audio_path, sr=sr, hop_length=hop_length, **rule_params)\n",
        "    if not use_model or model_path is None:\n",
        "        return rule_events\n",
        "    try:\n",
        "        model = PedalCNN(in_ch=1)\n",
        "        ckpt = torch.load(model_path, map_location=device)\n",
        "        if isinstance(ckpt, dict) and 'state_dict' in ckpt:\n",
        "            model.load_state_dict(ckpt['state_dict'])\n",
        "        else:\n",
        "            model.load_state_dict(ckpt)\n",
        "        model_events = predict_pedal_with_model(audio_path, model, device=device, hop_length=hop_length, threshold=model_threshold)\n",
        "        combined = rule_events.copy()\n",
        "        for me in model_events:\n",
        "            if not any((abs(me[0]-re[0])<0.05 and abs(me[1]-re[1])<0.05) for re in combined):\n",
        "                combined.append(me)\n",
        "        combined = sorted(combined, key=lambda x: x[0])\n",
        "        merged=[]\n",
        "        for s,e in combined:\n",
        "            if not merged:\n",
        "                merged.append([s,e])\n",
        "            else:\n",
        "                if s <= merged[-1][1] + 0.05:\n",
        "                    merged[-1][1] = max(merged[-1][1], e)\n",
        "                else:\n",
        "                    merged.append([s,e])\n",
        "        return [(s,e) for s,e in merged]\n",
        "    except Exception:\n",
        "        return rule_events\n",
        "\n",
        "# ---------------- MIDI에 페달 CC 삽입 ----------------\n",
        "def insert_pedal_cc_into_midi(midi_in_path, midi_out_path, pedal_events, piano_program=0):\n",
        "    pm = pretty_midi.PrettyMIDI(midi_in_path)\n",
        "    for inst in pm.instruments:\n",
        "        inst.program = piano_program\n",
        "    target_inst = pm.instruments[0] if pm.instruments else pretty_midi.Instrument(program=piano_program)\n",
        "    if not pm.instruments:\n",
        "        pm.instruments.append(target_inst)\n",
        "    for (s,e) in pedal_events:\n",
        "        on_time = max(0.0, s - 0.02); off_time = e + 0.02\n",
        "        target_inst.control_changes.append(pretty_midi.ControlChange(number=64, value=127, time=on_time))\n",
        "        target_inst.control_changes.append(pretty_midi.ControlChange(number=64, value=0, time=off_time))\n",
        "    for inst in pm.instruments:\n",
        "        inst.control_changes.sort(key=lambda cc: cc.time)\n",
        "    pm.write(midi_out_path)\n",
        "\n",
        "# ---------------- fluidsynth 렌더링 ----------------\n",
        "def render_midi_to_wav(midi_path, wav_out_path, sf2_path, sample_rate=44100):\n",
        "    if sf2_path is None or not os.path.exists(sf2_path):\n",
        "        return None\n",
        "    try:\n",
        "        cmd = ['fluidsynth', '-ni', sf2_path, midi_path, '-F', wav_out_path, '-r', str(sample_rate)]\n",
        "        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        return wav_out_path\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# ---------------- 체크포인트 ----------------\n",
        "def load_state():\n",
        "    if os.path.exists(STATE_FILE):\n",
        "        with open(STATE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    return {\"processed\": [], \"failed\": [], \"items\": {}, \"last_update\": None}\n",
        "\n",
        "def save_state(state):\n",
        "    state[\"last_update\"] = time.time()\n",
        "    with open(STATE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(state, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# ---------------- 항목 처리 (통합) ----------------\n",
        "def process_item_from_url_or_path(item, sf2_path=None, tmp_dir=None, pedal_model_path=None, use_pedal_model=False):\n",
        "    \"\"\"\n",
        "    item: YouTube URL 또는 로컬 오디오 파일 경로\n",
        "    pedal_model_path: (선택) 경량 페달 모델 체크포인트 경로\n",
        "    use_pedal_model: 모델 보조 사용 여부\n",
        "    \"\"\"\n",
        "    if tmp_dir is None:\n",
        "        tmp_dir = os.path.join(WORK_ROOT, \"tmp_\" + uuid.uuid4().hex)\n",
        "    os.makedirs(tmp_dir, exist_ok=True)\n",
        "    try:\n",
        "        # 1) 오디오 확보\n",
        "        if isinstance(item, str) and item.startswith(\"http\"):\n",
        "            mp3 = download_youtube_audio_single(item, tmp_dir, fmt=\"mp3\")\n",
        "        else:\n",
        "            mp3 = item\n",
        "\n",
        "        # 2) 전사 (ByteDance)\n",
        "        mid = transcribe_file(mp3, outfolder=tmp_dir)\n",
        "\n",
        "        # 3) 페달 검출 (규칙 기반 또는 모델 보조)\n",
        "        pedals = detect_pedal_lightweight(mp3, use_model=use_pedal_model, model_path=pedal_model_path, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # 4) MIDI에 CC 삽입\n",
        "        mid_pedal = os.path.join(tmp_dir, os.path.splitext(os.path.basename(mid))[0] + \"_pedal.mid\")\n",
        "        insert_pedal_cc_into_midi(mid, mid_pedal, pedals, piano_program=0)\n",
        "\n",
        "        # 5) Drive에 저장\n",
        "        saved_mp3 = os.path.join(DRIVE_RESULTS_DIR, os.path.basename(mp3)); shutil.copy(mp3, saved_mp3)\n",
        "        saved_midi = os.path.join(DRIVE_RESULTS_DIR, os.path.basename(mid_pedal)); shutil.copy(mid_pedal, saved_midi)\n",
        "\n",
        "        # 6) 렌더링 (선택)\n",
        "        saved_wav = None\n",
        "        if sf2_path:\n",
        "            wav_out = os.path.join(tmp_dir, os.path.splitext(os.path.basename(mp3))[0] + \"_render.wav\")\n",
        "            rendered = render_midi_to_wav(mid_pedal, wav_out, sf2_path)\n",
        "            if rendered:\n",
        "                saved_wav = os.path.join(DRIVE_RESULTS_DIR, os.path.basename(wav_out)); shutil.copy(wav_out, saved_wav)\n",
        "\n",
        "        return {\"status\":\"ok\", \"mp3\": saved_mp3, \"midi\": saved_midi, \"wav\": saved_wav, \"pedals\": pedals}\n",
        "    except Exception as e:\n",
        "        return {\"status\":\"error\", \"error\": str(e), \"trace\": traceback.format_exc()}\n",
        "\n",
        "# ---------------- 파일 업로드 처리 ----------------\n",
        "def process_files(gr_files,\n",
        "                  sf2_choice,\n",
        "                  uploaded_sf2,\n",
        "                  use_pedal_model=False,\n",
        "                  pedal_model_path=None,\n",
        "                  sustain_tolerance=0.2,\n",
        "                  pedal_energy_smooth=0.5,\n",
        "                  pedal_low_freq_cut=500,\n",
        "                  pedal_low_energy_weight=0.6,\n",
        "                  pedal_flux_weight=0.4,\n",
        "                  pedal_on_threshold=1.0,\n",
        "                  pedal_off_threshold=0.7,\n",
        "                  pedal_min_event_len=0.08,\n",
        "                  pedal_merge_gap=0.08):\n",
        "    \"\"\"\n",
        "    Gradio 파일 업로드용 래퍼. use_pedal_model, pedal_model_path 인자를 통해 모델 보조 사용 가능.\n",
        "    \"\"\"\n",
        "    chosen_sf2 = None\n",
        "    if sf2_choice and sf2_choice != \"None\":\n",
        "        chosen_sf2 = sf2_choice\n",
        "    if uploaded_sf2:\n",
        "        if isinstance(uploaded_sf2, list) and len(uploaded_sf2) > 0:\n",
        "            up = uploaded_sf2[0]\n",
        "            chosen_sf2 = up['name'] if isinstance(up, dict) and 'name' in up else up\n",
        "    if not gr_files:\n",
        "        return None, None\n",
        "    work_dir = \"/tmp/transcribe_\" + uuid.uuid4().hex\n",
        "    os.makedirs(work_dir, exist_ok=True)\n",
        "    local_paths = []\n",
        "    for f in gr_files:\n",
        "        if isinstance(f, dict) and 'name' in f:\n",
        "            local_paths.append(f['name'])\n",
        "        else:\n",
        "            local_paths.append(f)\n",
        "    midi_outs = []\n",
        "    for audio_path in local_paths:\n",
        "        try:\n",
        "            res = process_item_from_url_or_path(audio_path, sf2_path=chosen_sf2, tmp_dir=work_dir, pedal_model_path=pedal_model_path, use_pedal_model=use_pedal_model)\n",
        "            if res.get(\"status\") != \"ok\":\n",
        "                return f\"처리 실패: {res.get('error')}\", None\n",
        "            midi_outs.append(res.get(\"midi\"))\n",
        "        except Exception as e:\n",
        "            return f\"처리 중 예외: {e}\", None\n",
        "    if len(midi_outs) == 1:\n",
        "        final_midi = midi_outs[0]\n",
        "    else:\n",
        "        zip_path = os.path.join(work_dir, \"results_with_pedal.zip\")\n",
        "        with zipfile.ZipFile(zip_path, 'w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "            for p in midi_outs:\n",
        "                zf.write(p, arcname=os.path.basename(p))\n",
        "        final_midi = zip_path\n",
        "    wav_candidates = sorted(glob.glob(os.path.join(DRIVE_RESULTS_DIR, \"*_render.wav\")))\n",
        "    wav_path = wav_candidates[-1] if wav_candidates else None\n",
        "    return final_midi, wav_path\n",
        "\n",
        "# ---------------- 재생목록 제너레이터 ----------------\n",
        "def playlist_pipeline_generator(playlist_text, sf2_choice_path, use_pedal_model=False, pedal_model_path=None):\n",
        "    missing = []\n",
        "    for name in (\"expand_playlist_to_video_urls\", \"process_item_from_url_or_path\", \"load_state\", \"save_state\"):\n",
        "        if name not in globals():\n",
        "            missing.append(name)\n",
        "    if missing:\n",
        "        yield f\"필수 함수가 정의되어 있지 않습니다: {', '.join(missing)}\", None\n",
        "        return\n",
        "    lines = [ln.strip() for ln in str(playlist_text).splitlines() if ln.strip()]\n",
        "    items = []\n",
        "    for ln in lines:\n",
        "        if ln.startswith(\"http\") and (\"playlist\" in ln or \"list=\" in ln):\n",
        "            yield f\"재생목록 확장 중: {ln}\", None\n",
        "            try:\n",
        "                urls = expand_playlist_to_video_urls(ln)\n",
        "                if not urls:\n",
        "                    yield f\"재생목록에서 URL을 찾지 못했습니다: {ln}\", None\n",
        "                else:\n",
        "                    items.extend(urls)\n",
        "                    yield f\"재생목록에서 {len(urls)}개 항목 발견\", None\n",
        "            except Exception as e:\n",
        "                yield f\"재생목록 확장 실패: {e}\", None\n",
        "        else:\n",
        "            items.append(ln)\n",
        "    total = len(items)\n",
        "    if total == 0:\n",
        "        yield \"처리할 항목이 없습니다.\", None\n",
        "        return\n",
        "    try:\n",
        "        state = load_state()\n",
        "    except Exception as e:\n",
        "        yield f\"상태 파일 로드 실패: {e}\", None\n",
        "        return\n",
        "    yield f\"총 항목: {total}. 이미 처리된 항목: {len(state.get('processed', []))}. 처리 시작합니다...\", None\n",
        "    for idx, item in enumerate(items, start=1):\n",
        "        if item in state.get(\"processed\", []):\n",
        "            yield f\"[{idx}/{total}] 이미 처리됨: {item}\", None\n",
        "            continue\n",
        "        yield f\"[{idx}/{total}] 다운로드/전사 시작: {item}\", None\n",
        "        try:\n",
        "            res = process_item_from_url_or_path(item, sf2_path=sf2_choice_path, pedal_model_path=pedal_model_path, use_pedal_model=use_pedal_model)\n",
        "        except Exception as e:\n",
        "            res = {\"status\": \"error\", \"error\": str(e)}\n",
        "        if res.get(\"status\") == \"ok\":\n",
        "            state.setdefault(\"processed\", []).append(item)\n",
        "            state.setdefault(\"items\", {})[item] = {\n",
        "                \"mp3\": res.get(\"mp3\"),\n",
        "                \"midi\": res.get(\"midi\"),\n",
        "                \"wav\": res.get(\"wav\"),\n",
        "                \"time\": time.time()\n",
        "            }\n",
        "            try:\n",
        "                save_state(state)\n",
        "            except Exception as e:\n",
        "                yield f\"[{idx}/{total}] 완료했으나 상태 저장 실패: {e}\", res\n",
        "                continue\n",
        "            yield f\"[{idx}/{total}] 완료: {item} → MIDI: {os.path.basename(res.get('midi') or '')} WAV: {os.path.basename(res.get('wav') or '') or '없음'}\", res\n",
        "        else:\n",
        "            state.setdefault(\"failed\", []).append({\"item\": item, \"error\": res.get(\"error\")})\n",
        "            try:\n",
        "                save_state(state)\n",
        "            except Exception as e:\n",
        "                yield f\"[{idx}/{total}] 실패: {item} 에러 저장 실패: {e}\", None\n",
        "                continue\n",
        "            yield f\"[{idx}/{total}] 실패: {item} 에러: {res.get('error')}\", None\n",
        "    yield \"모든 항목 처리 완료(또는 건너뛰기 완료). Drive의 pipeline_state.json을 확인하세요.\", None\n",
        "\n",
        "print(\"통합 완료: ByteDance 전사 + 경량 페달 검출(규칙 기반 + 선택적 모델 보조) 파이프라인이 준비되었습니다.\")"
      ],
      "metadata": {
        "id": "r1ETPL5lHO9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 완전한 통합 UI 셀 — 업로드 탭 + 재생목록 탭, SF2 선택 포함 (단일 셀로 실행)\n",
        "# 이 셀은 이전에 정의된 함수들(process_files, playlist_pipeline_generator 등)을 사용합니다.\n",
        "# 만약 해당 함수들이 아직 정의되지 않았다면 먼저 관련 셀들을 실행하세요.\n",
        "\n",
        "import gradio as gr\n",
        "import os, traceback\n",
        "\n",
        "# sf2_files가 이미 존재하면 사용, 아니면 빈 리스트\n",
        "try:\n",
        "    sf2_choices = [\"None\"] + sf2_files\n",
        "except Exception:\n",
        "    sf2_choices = [\"None\"]\n",
        "\n",
        "def get_sf2_choice_value(choice, uploaded_sf2):\n",
        "    \"\"\"\n",
        "    UI에서 선택된 SF2 경로를 결정:\n",
        "    - uploaded_sf2가 있으면 업로드된 파일(첫번째)을 우선 사용\n",
        "    - 아니면 드롭다운 선택(choice)를 사용\n",
        "    \"\"\"\n",
        "    chosen = None\n",
        "    try:\n",
        "        if uploaded_sf2 and isinstance(uploaded_sf2, list) and len(uploaded_sf2) > 0:\n",
        "            up = uploaded_sf2[0]\n",
        "            if isinstance(up, dict) and 'name' in up:\n",
        "                chosen = up['name']\n",
        "            else:\n",
        "                chosen = up\n",
        "    except Exception:\n",
        "        chosen = None\n",
        "    if not chosen and choice and choice != \"None\":\n",
        "        chosen = choice\n",
        "    return chosen\n",
        "\n",
        "# 제너레이터 래퍼: 업로드 우선 SF2 결정 후 내부 제너레이터에 위임\n",
        "def playlist_wrapper_with_upload(playlist_text, sf2_choice_val, uploaded_sf2_val, sf2_direct_input):\n",
        "    try:\n",
        "        chosen = get_sf2_choice_value(sf2_choice_val, uploaded_sf2_val)\n",
        "        if sf2_direct_input:\n",
        "            chosen = sf2_direct_input\n",
        "        # playlist_pipeline_generator는 제너레이터여야 함\n",
        "        yield from playlist_pipeline_generator(playlist_text, chosen)\n",
        "    except Exception as e:\n",
        "        # 에러 발생 시 사용자에게 즉시 스트리밍 형태로 알림\n",
        "        yield f\"재생목록 처리 중 예외 발생: {e}\", None\n",
        "\n",
        "# 업로드 처리 콜백(동기 함수)\n",
        "def on_run_upload(gr_files, sf2_choice_val, uploaded_sf2_val,\n",
        "                  sustain_tolerance, pedal_energy_smooth, pedal_low_freq_cut,\n",
        "                  pedal_low_energy_weight, pedal_flux_weight,\n",
        "                  pedal_on_threshold, pedal_off_threshold,\n",
        "                  pedal_min_event_len, pedal_merge_gap):\n",
        "    try:\n",
        "        chosen_sf2 = get_sf2_choice_value(sf2_choice_val, uploaded_sf2_val)\n",
        "        status = f\"업로드 처리 시작. SF2: {os.path.basename(chosen_sf2) if chosen_sf2 else '없음'}\"\n",
        "        final_midi, wav_path = process_files(\n",
        "            gr_files,\n",
        "            sf2_choice=sf2_choice_val,\n",
        "            uploaded_sf2=uploaded_sf2_val,\n",
        "            sustain_tolerance=sustain_tolerance,\n",
        "            pedal_energy_smooth=pedal_energy_smooth,\n",
        "            pedal_low_freq_cut=pedal_low_freq_cut,\n",
        "            pedal_low_energy_weight=pedal_low_energy_weight,\n",
        "            pedal_flux_weight=pedal_flux_weight,\n",
        "            pedal_on_threshold=pedal_on_threshold,\n",
        "            pedal_off_threshold=pedal_off_threshold,\n",
        "            pedal_min_event_len=pedal_min_event_len,\n",
        "            pedal_merge_gap=pedal_merge_gap\n",
        "        )\n",
        "        return status, final_midi, wav_path\n",
        "    except Exception as e:\n",
        "        tb = traceback.format_exc()\n",
        "        return f\"업로드 처리 중 오류: {e}\\n{tb}\", None, None\n",
        "\n",
        "# Blocks UI 생성 및 실행\n",
        "with gr.Blocks() as combined_demo:\n",
        "    gr.Markdown(\"## 통합: 파일 업로드 + 재생목록 배치 처리 (공통 SF2 선택)\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            sf2_dropdown = gr.Dropdown(choices=sf2_choices, value=sf2_choices[0], label=\"Drive에서 선택할 SF2\")\n",
        "            sf2_upload = gr.Files(file_types=[\".sf2\"], label=\"또는 SF2 업로드 (선택)\")\n",
        "            gr.Markdown(\"**설명:** 업로드된 SF2가 있으면 업로드된 파일을 우선 사용합니다. 드롭다운에서 Drive에 복사된 SF2를 선택할 수도 있습니다.\")\n",
        "        with gr.Column(scale=2):\n",
        "            status_box = gr.Textbox(label=\"전역 상태\", interactive=False)\n",
        "            status_box.value = f\"결과 폴더: {DRIVE_RESULTS_DIR if 'DRIVE_RESULTS_DIR' in globals() else '설정 필요'}\"\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"파일 업로드 처리\"):\n",
        "            upload_files = gr.Files(file_types=[\".wav\", \".mp3\"], label=\"오디오 파일 업로드\")\n",
        "            sustain = gr.Slider(0.05, 0.6, value=0.2, step=0.01, label=\"Sustain tolerance (note merge, sec)\")\n",
        "            pedal_smooth = gr.Slider(0.1, 1.0, value=0.5, step=0.05, label=\"Pedal energy smoothing (sec)\")\n",
        "            pedal_lowcut = gr.Slider(200, 2000, value=500, step=50, label=\"Pedal low-frequency cutoff (Hz)\")\n",
        "            pedal_low_w = gr.Slider(0.0, 1.0, value=0.6, step=0.05, label=\"Low-energy weight (pedal)\")\n",
        "            pedal_flux_w = gr.Slider(0.0, 1.0, value=0.4, step=0.05, label=\"Flux weight (pedal)\")\n",
        "            pedal_on = gr.Slider(0.2, 2.0, value=1.0, step=0.1, label=\"Pedal ON threshold (sigma multiplier)\")\n",
        "            pedal_off = gr.Slider(0.0, 1.5, value=0.7, step=0.05, label=\"Pedal OFF threshold (sigma multiplier)\")\n",
        "            pedal_min = gr.Slider(0.02, 0.5, value=0.08, step=0.01, label=\"Min pedal event length (sec)\")\n",
        "            pedal_merge = gr.Slider(0.01, 0.3, value=0.08, step=0.01, label=\"Merge gap for pedal events (sec)\")\n",
        "            run_upload = gr.Button(\"업로드 파일 처리 시작\")\n",
        "            upload_result_file = gr.File(label=\"Download MIDI or ZIP\")\n",
        "            upload_preview = gr.Audio(label=\"Preview (WAV) - rendered with chosen SF2\", type=\"filepath\")\n",
        "\n",
        "            run_upload.click(\n",
        "                fn=on_run_upload,\n",
        "                inputs=[upload_files, sf2_dropdown, sf2_upload,\n",
        "                        sustain, pedal_smooth, pedal_lowcut, pedal_low_w, pedal_flux_w,\n",
        "                        pedal_on, pedal_off, pedal_min, pedal_merge],\n",
        "                outputs=[status_box, upload_result_file, upload_preview]\n",
        "            )\n",
        "\n",
        "        with gr.TabItem(\"재생목록 배치 처리\"):\n",
        "            playlist_input = gr.Textbox(lines=6, label=\"재생목록 URL 또는 영상 URL들 (줄바꿈으로 여러개 입력)\")\n",
        "            playlist_sf2_input = gr.Textbox(label=\"(선택) SF2 경로를 직접 입력하거나 위 드롭다운/업로드 사용\")\n",
        "            run_playlist_btn = gr.Button(\"재생목록 처리 시작\")\n",
        "            playlist_log = gr.Textbox(label=\"진행 로그\")\n",
        "            playlist_last = gr.JSON(label=\"마지막 항목 결과\")\n",
        "\n",
        "            # 제너레이터 래퍼를 직접 바인딩 (Gradio는 제너레이터 함수를 스트리밍으로 처리)\n",
        "            run_playlist_btn.click(\n",
        "                fn=playlist_wrapper_with_upload,\n",
        "                inputs=[playlist_input, sf2_dropdown, sf2_upload, playlist_sf2_input],\n",
        "                outputs=[playlist_log, playlist_last]\n",
        "            )\n",
        "\n",
        "    gr.Markdown(\"**사용법:** 상단에서 SF2를 드롭다운으로 선택하거나 SF2 파일을 업로드하세요. 업로드 탭은 로컬 파일을 처리하고, 재생목록 탭은 유튜브 재생목록/URL을 배치 처리합니다. 처리 결과는 Drive의 ytd_pipeline_results에 저장됩니다.\")\n",
        "\n",
        "# 실행 (Colab에서는 share=True, debug=False 권장)\n",
        "combined_demo.launch(share=True, debug=False)"
      ],
      "metadata": {
        "id": "iqUSEFdwHSPL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}